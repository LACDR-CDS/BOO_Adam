---
title: "BOO 2025"
subtitle: "Script 3: Sample QC"
date: "`r Sys.Date()`" 
author: 
  Adam Seuren
output:
  html_document:
    code_download: true
    theme: united
    highlight: tango
    df_print: paged
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

***

> In this script, you will perform sample-level quality control (QC), removing any poor quality samples and ensuring that experimental replicates are comparable to one another. 

***

# Setup

## Clean

As before, we perform several setup steps at the start of the script to ensure our work is reproducible and clear. 

**Exercise 1: Download the R markdown template and clean your environment:**

```{r clean}
# 
rm(list=ls())
```

***

## Set variables

**Exercise 2: Create the following objects in your R environment:**

* `root_dir` - project folder
* `count_path` - location of the `countData` object within the project folder
* `cpm_path` - location of the `cpmData` object
* `metadata_path` - location of the `metaData` object

* `count_store` - location to save the `countData` object within the project folder
* `cpm_store` - location to save the `cpmData` object
* `metadata_store` - location to save the filtered `metaData` after QC

* `count_threshold` - minimum library size required for samples (600,000; 20% of the target sequencing depth)
* `corr_threshold` - required correlation between replicates (0.9)

```{r set-variables}
#
root_dir <- "C:/Users/mmpse/Documents/GitHub/BOO-Adam/QC/03_Sample_QC/" 

count_path <- "Input/countData.Rdata" 
cpm_path <- "Input/cpmData.Rdata" 
metadata_path <- "Input/metaData.Rdata"

count_store <- "Output/countData.Rdata"
cpm_store <- "Output/cpmData.Rdata"
metadata_store <- "Output/metaData.Rdata" 

# Set count threshold to 600,000 - this is the minimum library size a sample needs to have. Including smaller samples would provide more unreliable data, as a small change in gene expression might look like a large effect.
count_threshold <- 6E5

# Set correlation threshold to 0.9 - it is important for the quality of the analysis that replicates of the same condition are correlated with each other
corr_threshold <- 0.9 
```

***

## Packages

Here, we load `tidyverse` and also a new package:

* `ggrepel` allows us labels in plots to "repel" each other and make visualizations clearer

**Exercise 3: Load `tidyverse` and `ggrepel` into your environment:**

```{r load-packages, warning=F, message=F}
#
library(tidyverse)
# ggrepel gives the possibility for labels in plots to stop overlapping with each other
library(ggrepel)
```

***

## Load data

**Exercise 4: Load the count data, CPM data, and metadata into your environment:**

<details>
  <summary><strong>Hint</strong></summary>

  Make sure these are the ones your saved at the end of the probe QC.

</details>

```{r load-data, warning=FALSE, message=FALSE}
#
load(paste0(root_dir, count_path))
load(paste0(root_dir, cpm_path))
load(paste0(root_dir, metadata_path))
```

***

# Library size

## Check

Before applying any filters, it is good to perform some checks.

**Exercise 5: Check that the column names of `countData` match the `sample_ID` order in `metaData`:**

```{r order-check}
# 
table(metaData$sample_ID == colnames(countData))
```
The function returns TRUE, so the column names of countData match the order of sample_ID in the metadata.
***

## Calculate

**Exercise 6: Now that we have removed unreliable and lowly expressed probes from `countData`, recalculate and save a new `lib_size` in the metadata:**

```{r calculate-lib}
# Summary of the unchanged lib_size
summary(metaData$lib_size)
```
Mean library size: 3740053
```{r}
# setting the library size as the total counts per sample of the updated countData
metaData$lib_size <- colSums(countData)

summary(metaData$lib_size)
```
Mean library size: 3614091. This is a bit smaller than before, as unreliable and lowly expressed probes have been removed from the countData.  
***

## Distribution

**Exercise 7: Make a histogram of `lib_size`. What range of values does this variable take and is this reasonable for a TempO-Seq experiment?**

```{r lib-histogram}
#
metaData %>% 
  # Creating a histogram of library size
  ggplot(aes(x = lib_size)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 30) +
  ggtitle("Histogram of library size values") + 
  xlab("Library size") +
  theme_bw()
```

The library size ranges from a bit over 2 million to a bit over 5 million reads, with an average around 3 million. This is a good amount for a TempOseq analysis, as the method is highly efficient.
***

## Flag

Samples whose library size is below 20% of the targeted sequencing depth (`corr_threshold`; 600,000) should be flagged as having low reads.

**Exercise 8: Create a flag in `metaData` describing if samples have low reads or not:**

```{r lib-flag}
metaData <- metaData %>% 
  # A column called flagLowReads is added to the metadata, which tells the reader whether or not the sample library size is above the threshold.
  mutate(flagLowReads = ifelse(lib_size <= count_threshold, T, F))

table(metaData$flagLowReads)
```
All values in the new column return false, which means that no sample library size is below the count threshold of 600000. 
***

## Plot

It is good to visualize the library size for each sample, grouped by compound ID. This shows us whether samples are well above the threshold, and allows us to inspect the data more carefully.

**Exercise 9: Create a boxplot for the library sizes of each compound (including DMSO) and describe any patterns you identify:**

<details>
  <summary><strong>Hint</strong></summary>

  You can colour your boxplots by concentration to visualize patterns more clearly.

</details>

```{r lib-boxplot}
#
metaData %>%   
  # concentration ID is made into a factor, so it can be used to color the boxplot by
  mutate(conc_ID = factor(conc_ID)) %>%   
  # library size is plotted against compound ID; we want to view the library size per condition
  ggplot(aes(x=compound_ID, y=lib_size)) + 
  # The plot is colored by concentration
  geom_boxplot(aes(color=conc_ID), width=0.8) +  
  # A dashed line is drawn at the minimum library size of 600000 counts.
  geom_hline(aes(yintercept=count_threshold), color="black", linetype="dashed") +
  # values below the threshold are labelled
  geom_text_repel(aes(x = compound_ID, y = lib_size, color = conc_ID),   
                   label=ifelse(metaData$lib_size < count_threshold, 
                                metaData$rep, "")) +

  xlab("") + ylab("Library size") + ggtitle("Library size distributions per condition") +    
  theme_bw()                                  
```

The library sizes per condition are relatively comparable to each other. Library sizes in the highest concentrations of both treatment conditions are smaller than the library sizes of the conditions of the lower concentrations; this could point to cytotoxicity, as dying cells do not express es much DNA.
***

# Replicate correlation

## log2CPM

The replicate correlation filter aims to remove any outlying replicates, with maximum pairwise correlations below the `corr_threshold` (set to 0.9). We usually perform this correlation analysis on the log2CPM values to ensure highly expressed genes do not have undue influence on the correlation values. A value of 1 is added to the CPM, to prevent issues arising from the fact that `log2(0)` is `-Inf`. 

**Exercise 10: Calculate and store the log2(CPM + 1) values in a `logcpmData` object:**

```{r log2cpm}
# the log2(cpm + 1) is calculated and stored
logcpmData <- log2(cpmData + 1)
```

***

## Pairwise correlations

In order to calculate pairwise correlations, each sample needs to be compared to the other replicates in its experimental group. We can do this by looping through `mean_ID`.

**Exercise 11: Calculate the pairwise replicate correlations for this data:**

<details>
  <summary><strong>Hint</strong></summary>

  The correlation can be calculated using `cor(cpmDataReps[,j], cpmDataReps[,k])` within an appropriate loop.

</details>

```{r pairwise-corr}
# A data frame is made for the output of the replicate filter
replicateFilterOutput <- data.frame()

# A loop is made with an iteration for each unique condition
for(i in unique(metaData$mean_ID)){
  # The metadata is filtered to only show data from the current mean_id
  metaDataReps <- metaData %>% 
    filter(mean_ID == i)
  
  # 
  cpmDataReps <- logcpmData[, metaDataReps$sample_ID] 
  
  #   
  for(j in 1:ncol(cpmDataReps)){
    # 
    for(k in 1:ncol(cpmDataReps)){
      # 
      sample_A <- colnames(cpmDataReps)[j]
      sample_B <- colnames(cpmDataReps)[k]
      
      # 
      if(sample_A != sample_B){
        # 
        r2 <- cor(cpmDataReps[,j], cpmDataReps[,k])
        
        # 
        replicateFilterOutput <- rbind(
          replicateFilterOutput, 
          data.frame(mean_ID = i, 
                     sample_A = sample_A,
                     sample_B = sample_B,
                     r2 = r2))
      }
    }
  }
}

# 
head(replicateFilterOutput)

```

***

## Maximum

Each sample is judged by the best pairwise correlation it can achieve. If this is below `corr_threshold`, the sample should be flagged.

**Exercise 12: Calculate the `max_r2` for each sample and add it to the `replicateFilterOutput`:**

```{r max-r2}
#

```

***

## Plot

**Exercise 13: Visualize the pairwise replicate correlations for each experimental conditions. Describe what you observe:**

```{r corr-boxplot}
#

```

***

## Flag

**Exercise 14: Flag any samples that did not pass the replicate correlation filter in the `metaData`:**

<details>
  <summary><strong>Hint</strong></summary>

  You can merge the replicate correlation filter output with the metaData to create a `max_r2` column after some processing.

</details>

```{r corr-flag}
#

```

***

# Advanced questions

If you would like a bit more of a challenge, here are a few extra questions relating to the two sample QC steps above. However, you can also skip these, save your data, and move on to the PCA.

## Library size

**Exercise 14: What are the benefits of a sample having a higher library size and does this benefit apply to some genes more than others?**

```{r read-depth}
#

```

***

## Replicate correlation

Instead of looking at pairwise correlations, another way of measuring how good a replicate is is by comparing it to the average for that experimental condition. 

**Exercise 15: Calculate replicate correlation in this way and see if it alters the results of this filter. What is one benefit and downside of assessing replicate correlation in this manner?**

```{r mean-corr}
#

```

***

# Save

**Exercise 16: Remove samples that did not pass the sample QC steps from your data:**

<details>
  <summary><strong>Hint</strong></summary>

  Don't forget to also subset the count and CPM data.

</details>

```{r any-flag}
#

```

***

## Save

**Exercise 17: Save the updated data:**

```{r save-metadata}
#

```

***

# Session Info

**Exercise 18: Print your session info at the end of the script, knit the R markdown document, and push it to GitHub:**

```{r session-info}
#

```

***

That is the end of the Sample QC. Example answers will be available from the `BOO_template` GitHub on Tuesday. 

Next, please move on to the PCA using `04_PCA_Outline.Rmd`.

***

